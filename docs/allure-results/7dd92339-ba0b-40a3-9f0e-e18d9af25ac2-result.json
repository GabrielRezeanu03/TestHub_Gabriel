{"name": "test_scrapers_city[nokiaScraper]", "status": "broken", "statusDetails": {"message": "requests.exceptions.ChunkedEncodingError: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))", "trace": "self = <urllib3.response.HTTPResponse object at 0x7f00db5aa7a0>\n\n    @contextmanager\n    def _error_catcher(self) -> typing.Generator[None, None, None]:\n        \"\"\"\n        Catch low-level python exceptions, instead re-raising urllib3\n        variants, so that low-level exceptions are not leaked in the\n        high-level api.\n    \n        On exit, release the connection back to the pool.\n        \"\"\"\n        clean_exit = False\n    \n        try:\n            try:\n>               yield\n\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/urllib3/response.py:737: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/urllib3/response.py:1170: in read_chunked\n    self._update_chunk_length()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <urllib3.response.HTTPResponse object at 0x7f00db5aa7a0>\n\n    def _update_chunk_length(self) -> None:\n        # First, we'll figure out length of a chunk and then\n        # we'll try to read it from socket.\n        if self.chunk_left is not None:\n            return None\n        line = self._fp.fp.readline()  # type: ignore[union-attr]\n        line = line.split(b\";\", 1)[0]\n        try:\n            self.chunk_left = int(line, 16)\n        except ValueError:\n            # Invalid chunked protocol response, abort.\n            self.close()\n>           raise InvalidChunkLength(self, line) from None\nE           urllib3.exceptions.InvalidChunkLength: InvalidChunkLength(got length b'', 0 bytes read)\n\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/urllib3/response.py:1105: InvalidChunkLength\n\nThe above exception was the direct cause of the following exception:\n\n    def generate():\n        # Special case for urllib3.\n        if hasattr(self.raw, \"stream\"):\n            try:\n>               yield from self.raw.stream(chunk_size, decode_content=True)\n\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/requests/models.py:816: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/urllib3/response.py:1030: in stream\n    yield from self.read_chunked(amt, decode_content=decode_content)\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/urllib3/response.py:1158: in read_chunked\n    with self._error_catcher():\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <urllib3.response.HTTPResponse object at 0x7f00db5aa7a0>\n\n    @contextmanager\n    def _error_catcher(self) -> typing.Generator[None, None, None]:\n        \"\"\"\n        Catch low-level python exceptions, instead re-raising urllib3\n        variants, so that low-level exceptions are not leaked in the\n        high-level api.\n    \n        On exit, release the connection back to the pool.\n        \"\"\"\n        clean_exit = False\n    \n        try:\n            try:\n                yield\n    \n            except SocketTimeout as e:\n                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\n                # there is yet no clean way to get at it from this context.\n                raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    \n            except BaseSSLError as e:\n                # FIXME: Is there a better way to differentiate between SSLErrors?\n                if \"read operation timed out\" not in str(e):\n                    # SSL errors related to framing/MAC get wrapped and reraised here\n                    raise SSLError(e) from e\n    \n                raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    \n            except (HTTPException, OSError) as e:\n                # This includes IncompleteRead.\n>               raise ProtocolError(f\"Connection broken: {e!r}\", e) from e\nE               urllib3.exceptions.ProtocolError: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/urllib3/response.py:754: ProtocolError\n\nDuring handling of the above exception, another exception occurred:\n\nscraper_class = <class 'sites.nokia.nokiaScraper'>\n\n    @pytest.fixture(scope=\"class\")\n    def setup_tests(scraper_class):\n        \"\"\"\n        Fixture for setting up tests with the provided scraper class.\n        \"\"\"\n        setup_tests_instance = SetupTests()\n>       setup_tests_instance.get_jobs_careers(scraper_class)\n\ntests/test_api.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_api.py:32: in get_jobs_careers\n    self.scraper_data = scraper_class().return_data()\nsites/nokia.py:135: in return_data\n    self.post_response()\nsites/nokia.py:65: in post_response\n    response = requests.post('https://careers.nokia.com/ajax/content/job_results', params=self.params, cookies=self.cookies, headers=self.headers)\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/requests/api.py:115: in post\n    return request(\"post\", url, data=data, json=json, **kwargs)\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/requests/api.py:59: in request\n    return session.request(method=method, url=url, **kwargs)\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/requests/sessions.py:589: in request\n    resp = self.send(prep, **send_kwargs)\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/requests/sessions.py:747: in send\n    r.content\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/requests/models.py:899: in content\n    self._content = b\"\".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b\"\"\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def generate():\n        # Special case for urllib3.\n        if hasattr(self.raw, \"stream\"):\n            try:\n                yield from self.raw.stream(chunk_size, decode_content=True)\n            except ProtocolError as e:\n>               raise ChunkedEncodingError(e)\nE               requests.exceptions.ChunkedEncodingError: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n\n/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/requests/models.py:818: ChunkedEncodingError"}, "parameters": [{"name": "scraper_class", "value": "<class 'sites.nokia.nokiaScraper'>"}], "start": 1706937239963, "stop": 1706937239963, "uuid": "8ad5c17f-a844-484f-9cc0-286d4126161f", "historyId": "2c9f88505d422763c07579c5c6e946f5", "testCaseId": "75f773d8d7bc6573a9e018ca8c499fa6", "fullName": "test_api.TestScrapers#test_scrapers_city", "labels": [{"name": "tag", "value": "API"}, {"name": "tag", "value": "regression"}, {"name": "suite", "value": "test_api"}, {"name": "subSuite", "value": "TestScrapers"}, {"name": "host", "value": "fv-az1381-620"}, {"name": "thread", "value": "1911-MainThread"}, {"name": "framework", "value": "pytest"}, {"name": "language", "value": "cpython3"}, {"name": "package", "value": "test_api"}]}